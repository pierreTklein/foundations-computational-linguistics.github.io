<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Coarse-to-Fine Inference</title>

    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap-theme.min.css">
    <link rel="stylesheet" href="/node_modules/codemirror/lib/codemirror.css">
    <link rel="stylesheet" href="/node_modules/codemirror/theme/neat.css">
    <link rel="stylesheet" href="/assets/css/katex.min.css">
    <link rel="stylesheet" href="/assets/css/custom.css">
    <link rel="stylesheet" href="/assets/css/code.css">

    <script src="/assets/js/webchurch.min.js"></script>
    <script src="/assets/js/katex.min.js"></script>
    <script src="/bower_components/jquery/dist/jquery.min.js"></script>
    <script src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="/node_modules/codemirror/lib/codemirror.js"></script>
    <script src="/node_modules/codemirror/mode/javascript/javascript.js"></script>
    <script src="/assets/js/cm-folding.js"></script>
    <script src="/assets/js/cm-comments.js"></script>
    <script src="/assets/js/webppl.min.js"></script>
    <script src="/bower_components/jquery-autosize/jquery.autosize.min.js"></script>
    <script src="/bower_components/d3/d3.min.js"></script>
    <script src="/bower_components/vega/vega.min.js"></script>
    <!-- <script src="https://probmods.org/webchurch/online/vega.min.js"></script> -->
    <script src="/bower_components/underscore/underscore.js"></script>
    <script src="/bower_components/react/JSXTransformer.js"></script>
    <script src="/bower_components/react/react-with-addons.min.js"></script>
    <script src="/bower_components/showdown/compressed/showdown.js"></script>
    <script src="/assets/js/custom.js"></script>
    <script type="text/jsx" src="/assets/js/editor.js"></script>

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

  </head>
  <body>

    <div class="navbar navbar-default navbar-static-top" role="navigation">
      <div class="container-fluid">
        <div class="navbar-header">
          <a class="navbar-brand" href="/">Computational Phonology and Morphology</a>
        </div>
        <ul class="nav navbar-nav navbar-right collapse navbar-collapse">
            <li><a href="/editor.html">Editor</a></li>
        </ul>
      </div>

    </div>

    <div class="container">

      <div class="page-header">
  <h1>Coarse-to-Fine Inference</h1>
</div>

<p>Let’s think about how to build a coarse-to-fine model for a simple probabilistic program.</p>

<p>We would like to transform the model such that we sample in a coarse-to-fine manner without changing the overall distribution. If the model includes factors, we would like to apply coarsened versions of these factors early on when we sample at the coarse level, and cancel out these “heuristic” factors when we get to the fine-grained level.</p>

<h2 id="abstract-objects-as-distributions">Abstract objects as distributions</h2>

<p>Here is our (fine-grained) program:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>// Wrap arithmetic primitives so that they are real functions

var times = function(x, y) {
  return x * y;
};

var minus = function(x) {
  return -x;
};


// A simple discrete random variable

var discreteSampler = function(vs, ps){
  return function(){
    var index = discrete(ps);
    return vs[index];
  };
};

var values = [1, 2, 3, 4];
var probs  = [.1, .2, .3, .4];
var fooSampler = discreteSampler(values, probs);


// Main program

var foo = function() {
  var x = fooSampler();
  var score = minus(times(x, 2));
  factor(score);
  return x;
};

print(Enumerate(foo));
</code></pre>
</div>

<p>Let’s first write some general-purpose functions that will come in handy later on. These are standard functional programming tools.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};
</code></pre>
</div>

<p>We’ll also need expectations (for erps) and delta distributions:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var expectation = function(erp, f){
  return sum(
    map(function(v){ return Math.exp(erp.score([], v)) * f(v); },
        erp.support([])));
};

var mean = function(erp){
  return expectation(erp, function(x){return x;});
}

var delta = function(x) {
  return discreteSampler([x], [1]);
};
</code></pre>
</div>

<p>Now let’s think about how to coarsen a sampler given a value abstraction function.</p>

<p>A value abstraction function sorts values into equivalence classes and looks like this:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>// static

var abstractValue = function(v){
  return {
    1: "a",
    2: "a",
    3: "b",
    4: "b"
  }[v];
};
</code></pre>
</div>

<p>The function <code class="highlighter-rouge">coarsen</code> will take a sampler (a thunk that probabilistically returns a value) and will turn it into a hierarchical sampler (a thunk that probabilistically returns a sampler) by grouping values as determined by the value abstraction function.</p>

<p>The hierarchical sampler first chooses a base-level sampler (according to the sum of the probabilities of all elements that are in the corresponding group), then samples from the values in the group (with renormalized) probabilities:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var coarsen = function(sampler, abstractValue){

  // Get sampler's distribution in explicit form

  var erp = Enumerate(sampler);
  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v))}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue(vp1[0]) == abstractValue(vp2[0]);
    },
    zip(allVs, allPs));

  var groupedVs = map(function(group){return map(group, first)}, groups);

  var groupedPs = map(function(group){return map(group, second)}, groups);

  // Construct hierarchical sampler

  var samplers = map2(discreteSampler, groupedVs, groupedPs);
  var samplerPs = map(sum, groupedPs);

  return discreteSampler(samplers, samplerPs);
};
</code></pre>
</div>

<p>Given a coarsening function, we can now lift primitive functions to operate on coarsened (i.e. hierarchical) samplers.</p>

<p>The general principle is as follows:</p>

<ol>
  <li>Compute the fine-grained distribution on return values that results when the primitive function is applied to the distribution on fine-grained values that corresponds to the coarsened input value.</li>
  <li>Coarsen this return distribution.</li>
</ol>

<p><em>However</em>, note that, in the implementation, we have to “flatten” the coarse input twice to get a concrete value. This is the case because, in our coarsened program, values will have been lifted to <em>distributions on distributions on values</em>.</p>

<p>To see why this is necessary, look at the return type for the lifting function: if we simply returned a sampler for <code class="highlighter-rouge">outputMarginal</code>, the return type would be a distribution on concrete values—there wouldn’t be any clustering based on the abstraction function. If we coarsen this distribution, then the return value is of type “distribution on distributions [on concrete values]”. In other words, the type is “distributions on abstract values”.</p>

<p>It is worth thinking about whether this is the right type for the coarsened program, but it seems that this type plays nicer with lossy coarsenings (which aren’t addressed in this note).</p>

<p>We’ll write two separate versions of the lifting function here, one for primitives of one argument, and one for primitives that take two arguments.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var lift1 = function(f, abstractValue){
  return function(coarseInput){
    var outputMarginal = Enumerate(
      function(){
        var d = coarseInput();
        var v = d();
        return f(v);
      });
    return coarsen(
      function(){ return sample(outputMarginal); },
      abstractValue);
  };
};

var lift2 = function(f, abstractValue){
  return function(coarseInput1, coarseInput2){
    var outputMarginal = Enumerate(
      function(){
        var d1 = coarseInput1();
        var d2 = coarseInput2();
        var v1 = d1();
        var v2 = d2();
        return f(v1, v2);
      });
    return coarsen(
      function(){ return sample(outputMarginal); },
      abstractValue);
  };
};
</code></pre>
</div>

<p>Now let’s wrap up our expectation function so that it can apply to coarse values (i.e. to distributions on distributions on concrete values):</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var cExpectation = function(cSampler, f){
  return expectation(
    Enumerate(function(){
                var d = cSampler();
                var x = d();
                return x;
              }),
    f);
};

var cMean = function(cSampler){
  return cExpectation(cSampler, function(x){return x;});
}
</code></pre>
</div>

<p>With these preliminaries out of the way, we can now pick an abstraction function and write our coarse-to-fine model.</p>

<p>The abstraction function simply groups values into equivalence classes. We arbitrarily pick this one:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var abstractValue = function(v){
  return {
    1: "a",
    2: "a",
    3: "b",
    4: "b",
    5: "c",
    6: "c",
    7: "c",
    8: "c"
  }[v];
};
</code></pre>
</div>

<p>The coarse-to-fine model consists of two parts, a coarse part and a fine part. We first sample and score (using factors) on the coarse level, then refine to the concrete level and adjusts the score.</p>

<p>The coarse part operates on distributions on distributions on concrete values. We coarsen random variables (here: <code class="highlighter-rouge">fooSampler</code> becomes <code class="highlighter-rouge">cFooSampler</code>) and lift primitive functions (<code class="highlighter-rouge">times</code>, <code class="highlighter-rouge">minus</code>) to operate on coarse values.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>// Data from original program

var values = [1, 2, 3, 4];
var probs  = [.1, .2, .3, .4];
var fooSampler = discreteSampler(values, probs);


// Coarse-to-fine program

var cFooSampler = coarsen(fooSampler, abstractValue);
var cTimes = lift2(times, abstractValue);
var cMinus = lift1(minus, abstractValue);

var ctfFoo = function() {

  var cX = delta(cFooSampler());
  var cY = cMinus(cTimes(cX, delta(delta(2))));
  var cScore = cMean(cY);
  factor(cScore);

  var x = cX()();
  var score = minus(times(x, 2));
  factor(score - cScore);
  return x;

};

print(Enumerate(ctfFoo));
</code></pre>
</div>

<p>Note that the distribution on return values is exactly the same as for the original program.</p>

<p>Open questions:</p>

<ul>
  <li>Is “distributions on distributions on fine-grained values” a good type for the coarse program?</li>
  <li>How can we apply this approach to images and similar settings where (a) it is difficult to keep track of distributions on objects and (b) we might therefore want to just use coarse-grained objects (such as downsampled images) directly, and apply primitive operations directly?</li>
  <li>What does a program transform look that makes it feasible to apply this approach to more complex programs? For example, think of recursive programs like the HMM.</li>
  <li>How can we extend this approach to play nicely with hierarchical coarsening?</li>
  <li>How useful/efficient is this in general? In this example, we use enumeration and don’t use any caching. In real-world examples, we might have to use sampling, and most likely would need to use caching in various places.</li>
</ul>

<h2 id="abstract-objects-as-symbols">Abstract objects as symbols</h2>

<p>Now let’s think about how to build a coarse-to-fine program in a more direct style. Now, the values in the program are going to be the symbols returned by <code class="highlighter-rouge">abstractValue</code>, ERPs are split into a distribution on abstract values and a conditional distribution on concrete values given an abstract value, and deterministic primitives are lifted to stochastic functions on abstract values.</p>

<p>We start with an <code class="highlighter-rouge">abstractValue</code> map (previously, this was a function):</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var abstractValue = {
  1: "a",
  2: "a",
  3: "b",
  4: "b",
  5: "c",
  6: "c",
  7: "c",
  8: "c"
}
</code></pre>
</div>

<p>Suppose we have a discrete ERP:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var discreteSampler = function(vs, ps){
  return function(){
    var index = discrete(ps);
    return vs[index];
  };
};

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}

var myERP = makeERP([.1, .2, .3, .4], [1, 2, 3, 4]);

print(myERP)
</code></pre>
</div>

<p>Coarsening this ERP means splitting it into two parts: an unconditional sampler on abstract values and a conditional sampler on concrete values:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};
///

var coarsen = function(erp, abstractValue){

  // Get concrete values and probabilities

  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v));}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue[vp1[0]] == abstractValue[vp2[0]];
    },
    zip(allVs, allPs));

  var groupSymbols = map(
    function(group){
      // group[0][0]: first value in group
      return abstractValue[group[0][0]]},
    groups);

  var groupedVs = map(
    function(group){
      return map(group, first);},
	groups);

  var groupedPs = map(
    function(group){
      return map(group, second);},
	groups);

  // Construct unconditional (abstract) sampler and
  // conditional (concrete) sampler

  var abstractPs = map(sum, groupedPs);
  var abstractSampler = makeERP(abstractPs, groupSymbols);

  var groupERPs = map2(makeERP, groupedPs, groupedVs);
  var getConcreteSampler = function(abstractSymbol){
    var i = indexOf(abstractSymbol, groupSymbols);
    return groupERPs[i];
  }

  return [abstractSampler, getConcreteSampler];

}
</code></pre>
</div>

<p>We’re now going to verify that chaining the two erps is equivalent to the original ERP.</p>

<p>Here is the original distribution:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var myERP = makeERP([.1, .2, .3, .4], [1, 2, 3, 4]);

print(myERP)
</code></pre>
</div>

<p>Here is the chained distribution:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var abstractValue = {
  1: "a",
  2: "a",
  3: "b",
  4: "b",
  5: "c",
  6: "c",
  7: "c",
  8: "c"
}

var myERP = makeERP([.1, .2, .3, .4], [1, 2, 3, 4]);

var tmp = coarsen(myERP, abstractValue);

var myAbstractERP = tmp[0];
var getConcreteERP = tmp[1];

print(
  Enumerate(
    function(){
      var x = sample(myAbstractERP);
      var y = sample(getConcreteERP(x));
      return y
    }))
</code></pre>
</div>

<p>Besides coarsening erps, we also need to lift primitive functions.</p>

<p>We will face a choice here:</p>

<p>Suppose there are two erps with the same support, but different distributions. When we coarsened an erp, we used the erps particular distribution in the second step to concretize the abstract value.</p>

<p>When we get to a primitive function (which will now be lifted to a primitive function on abstract values), do we use this particular distribution, or do we associate with each abstract symbol a single distribution (e.g. maximum entropy) that we use at primitives?</p>

<p>Let’s work out a particular example. Here is what our original (uncoarsened) program could look like:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var abstractValue = {
  1: "a",
  2: "a",
  3: "b",
  4: "b",
  5: "c",
  6: "c",
  7: "c",
  8: "c"
}

var erp1 = makeERP([.1, .2, .3, .4], [1, 2, 3, 4]);
var erp2 = makeERP([.25, .25, .25, .25], [1, 2, 3, 4]);

var tmp1 = coarsen(erp1, abstractValue);
var abstractERP1 = tmp1[0];
var conditionalERP1 = tmp1[1];

var tmp2 = coarsen(erp2, abstractValue);
var abstractERP2 = tmp2[0];
var conditionalERP2 = tmp2[1];
</code></pre>
</div>

<p>Now <code class="highlighter-rouge">abstractERP1</code> and <code class="highlighter-rouge">abstractERP2</code> operate on the same abstract values, but strictly speaking, they have different meanings, because they are going to be refined differently when they hit their corresponding conditional ERPs.</p>

<p>We could treat them differently at primitives as well, which would in effect mean that the two erps actually <strong>don’t</strong> share abstract values.</p>

<p>This has the drawback that we need to learn the distributions for lifted primitives independently.</p>

<p>Let’s think about a simpler, but more complete example:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var erp1 = makeERP([.9, .1], [true, false]);
var erp2 = makeERP([.1, .9], [true, false]);

var newAbstractValue = {
  true: "a",
  false: "a"
}

var tmp1 = coarsen(erp1, newAbstractValue);
var abstractERP1 = tmp1[0];
var conditionalERP1 = tmp1[1];

var tmp2 = coarsen(erp2, newAbstractValue);
var abstractERP2 = tmp2[0];
var conditionalERP2 = tmp2[1];

var program = function(){

  var cX = abstractERP1();
  var cY = abstractERP2();
  var cOut = cAnd(cX, cY);
  var cScore = cExpectation(cOut c? -1 : -2);
  factor(cScore);

  var x = conditionalERP1(cX);
  var y = conditionalERP2(cY);
  var out = and(x, y);
  var score = out ? -1 : -2;
  factor(score - cScore);

}
</code></pre>
</div>

<p>At the point where we compute <code class="highlighter-rouge">cOut</code>, we need to get an abstract return value. This is easy because there is only a single abstract value, so the distribution is clear - this single value has probability 1.</p>

<p>At the point where we compute <code class="highlighter-rouge">cScore</code>, we need to turn <code class="highlighter-rouge">cOut</code> back into concrete Boolean values. What distribution do we use here? One option is to use a maximum entropy distribution (or other canonical choice). This will work fine, because we cancel out the coarse factor later on.</p>

<p>The example above doesn’t address stochastic choice at primitive functions, so let’s extend the example such that it does.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var erp1 = makeERP([.9, .05, .05], [0, 1, 2]);
var erp2 = makeERP([.05, .05, .9], [0, 1, 2]);

var newAbstractValue = {
  0: "a",
  1: "b",
  2: "b"
}

var tmp1 = coarsen(erp1, newAbstractValue);
var abstractERP1 = tmp1[0];
var conditionalERP1 = tmp1[1];

var tmp2 = coarsen(erp2, newAbstractValue);
var abstractERP2 = tmp2[0];
var conditionalERP2 = tmp2[1];

var program = function(){

  var cX = abstractERP1();
  var cY = abstractERP2();
  var cOut = cAnd(cX, cY);
  var cScore = cExpectation(cOut c? -1 : -2);
  factor(cScore);

  var x = conditionalERP1(cX);
  var y = conditionalERP2(cY);
  var out = and(x, y);
  var score = out ? -1 : -2;
  factor(score - cScore);

}
</code></pre>
</div>

<p>Now it’s less clear what should happen at <code class="highlighter-rouge">cAnd</code>. We get two abstract values (such as “a” and “b”) and we need to stochastically sample an output value in the same domain. Actually, even here it is still relatively clear what should happen - we know that the first argument to <code class="highlighter-rouge">cAnd</code> is coming from <code class="highlighter-rouge">cX</code>, and that the second argument is coming from <code class="highlighter-rouge">cY</code>, and so we could concretize them according to their corresponding distributions. We could then apply the underlying concrete <code class="highlighter-rouge">and</code> functions to these concretized values, and go back to the abstract domain by grouping concrete values according to the abstraction function and choosing with the corresponding probabilities.</p>

<p>Let’s briefly think about the question whether we should think about the same abstract symbols as denoting the same distributions on concrete values. My currently favored answer is: yes, for the purpose of running the abstract program, we should do exactly that. No, for the purpose of refining the abstract program to the concrete program, we should look at the actual conditional distributions.</p>

<p>Claim: If all the erps in the abstract program are independent, if the erps are factored such that we get back the original erps if chained together, and if we cancel out all abstract factors later on, we can do more or less whatever we want. In particular, we can associate fixed (e.g. maxent) distributions with abstract symbols for the purpose of lifting primitives. We can then independently solve the problem of what coarsenings (what <code class="highlighter-rouge">abstractValue</code> functions together with distributions on concrete symbols) work well.</p>

<p>(This may resolve the problem of what to do about images - if we can sample a coarse image, do whatever we want, including apply factors to it, and then later on refine and correct the factors.)</p>

<p>It may seem surprising that the particular choice of refinement distribution for the purpose of lifting doesn’t matter for correctness.</p>

<p>(Question for later: what about conditional erps in the concrete program?)</p>

<p>Let’s make the example a little more complex, and then let’s work it out in all detail.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var erp1 = makeERP([.9, .05, .05], [0, 1, 2]);
var erp2 = makeERP([.05, .05, .9], [0, 1, 2]);
var erp3 = makeERP([.05, .2, .75], [0, 1, 2]);

var newAbstractValue = {
  0: "a",
  1: "b",
  2: "b"
}

var tmp1 = coarsen(erp1, newAbstractValue);
var abstractERP1 = tmp1[0];
var conditionalERP1 = tmp1[1];

var tmp2 = coarsen(erp2, newAbstractValue);
var abstractERP2 = tmp2[0];
var conditionalERP2 = tmp2[1];

var tmp3 = coarsen(erp3, newAbstractValue);
var abstractERP3 = tmp3[0];
var conditionalERP3 = tmp3[1];

var program = function(){

  var cX = abstractERP1();
  var cY = abstractERP2();
  var cZ = abstractERP3();

  var cOut1 = cOr(cX, cY);
  var cOut2 = cOr(cY, cZ);
  var cScore = cExpectation((cOut1 c&amp; cOut2) c? -1 : -2);
  factor(cScore);

  var x = conditionalERP1(cX);
  var y = conditionalERP2(cY);
  var z = conditionalERP3(cZ);
  var out1 = or(x, y);
  var out2 = or(y, z);
  var score = (out1 &amp; out2)  ? -1 : -2;
  factor(score - cScore);

}
</code></pre>
</div>

<p>Now it’s impossible for <code class="highlighter-rouge">cOr</code> to know the exact distribution its first argument was sampled from. All it knows is its abstract value, which is associated with a particular support on concrete values.</p>

<p>Okay, now that we have a sense for what the general approach should be, let’s go back to the start and let’s make it concrete.</p>

<p>Here is the program that we are going to try to coarsen:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>// Turn special operators into functions

var or = function(x, y){
  return x | y;
}

var and = function(x, y){
  return x &amp; y;
}

var ternary = function(test, then, other){
  return test ? then : other;
}

// Construct random variables

var erp1 = makeERP([.9, .05, .05], [0, 1, 2]);
var erp2 = makeERP([.05, .05, .9], [0, 1, 2]);
var erp3 = makeERP([.05, .2, .75], [0, 1, 2]);

// Main program

var program = function(){

  var x = sample(erp1);
  var y = sample(erp2);
  var z = sample(erp3);
  var out1 = or(x, y);
  var out2 = or(y, z);
  var score = ternary(and(out1, out2), -1, -2);
  factor(score);
  return [x, y, z];

}

print(Enumerate(program));
</code></pre>
</div>

<p>Let’s write a lifting function that can make the primitives (<code class="highlighter-rouge">or</code>, <code class="highlighter-rouge">and</code>, <code class="highlighter-rouge">ternary</code>) operate on abstract values.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var preImage = function(cV, allVs, abstractValue){
  if (allVs.length == 0) {
    return []
  } else {
    var remainder = preImage(cV, allVs.slice(1), abstractValue);
    if (cV == abstractValue[allVs[0]]) {
      return [allVs[0]].concat(remainder);
    } else {
      return remainder;
    }
  }
}

var maxEntERP = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  // get all values that map to cV
  var vs = preImage(cV, allVs, abstractValue);
  // return uniform distribution on these values
  return Enumerate(
    function(){
      return vs[randomInteger(vs.length)];
    });
}

// Do we really not need to marginalize here?

var lift1 = function(f, abstractValue){
  return function(cX){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var x = sample(d1);
    var out = f(x);
    return abstractValue[out];
  }
}

var lift2 = function(f, abstractValue){
  return function(cX, cY){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var out = f(x, y);
    return abstractValue[out];
  }
}

var lift3 = function(f, abstractValue){
  return function(cX, cY, cZ){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var d3 = maxEntERP(cZ, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var z = sample(d3);
    var out = f(x, y, z);
    return abstractValue[out];
  }
}

var abstractValue = {
  0: "a",
  1: "b",
  2: "b"
}

print(maxEntERP("b", abstractValue))
</code></pre>
</div>

<p>Now we are ready to lift the primitives in the program above and build the coarse-to-fine model.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}

var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};

var coarsen = function(erp, abstractValue){

  // Get concrete values and probabilities

  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v));}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue[vp1[0]] == abstractValue[vp2[0]];
    },
    zip(allVs, allPs));

  var groupSymbols = map(
    function(group){
      // group[0][0]: first value in group
      return abstractValue[group[0][0]]},
	groups)

  var groupedVs = map(function(group){return map(group, first);}, groups);

  var groupedPs = map(function(group){return map(group, second);}, groups);

  // Construct unconditional (abstract) sampler and
  // conditional (concrete) sampler

  var abstractPs = map(sum, groupedPs);
  var abstractSampler = makeERP(abstractPs, groupSymbols);

  var groupERPs = map2(makeERP, groupedPs, groupedVs);
  var getConcreteSampler = function(abstractSymbol){
    var i = indexOf(abstractSymbol, groupSymbols);
    return groupERPs[i];
  }

  return [abstractSampler, getConcreteSampler];

}

var preImage = function(cV, allVs, abstractValue){
  if (allVs.length == 0) {
    return []
  } else {
    var remainder = preImage(cV, allVs.slice(1), abstractValue);
    if (cV == abstractValue[allVs[0]]) {
      return [allVs[0]].concat(remainder);
    } else {
      return remainder;
    }
  }
}

var maxEntERP = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  // get all values that map to cV
  var vs = preImage(cV, allVs, abstractValue);
  // return uniform distribution on these values
  return Enumerate(
    function(){
      return vs[randomInteger(vs.length)];
    });
}

// Do we really not need to marginalize here?

var lift1 = function(f, abstractValue){
  return function(cX){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var x = sample(d1);
    var out = f(x);
    return abstractValue[out];
  }
}

var lift2 = function(f, abstractValue){
  return function(cX, cY){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var out = f(x, y);
    return abstractValue[out];
  }
}

var lift3 = function(f, abstractValue){
  return function(cX, cY, cZ){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var d3 = maxEntERP(cZ, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var z = sample(d3);
    var out = f(x, y, z);
    return abstractValue[out];
  }
}

///


// Abstraction map

var abstractValue = {
  "-2": -2,
  "-1": -1,
  0: "a",
  1: "b",
  2: "b"
}


// Turn special operators into functions

var or = function(x, y){
  return (x | y) ? 1 : 0;
}

var and = function(x, y){
  return (x &amp; y) ? 1 : 0;
}

var ternary = function(test, then, other){
  return test ? then : other;
}


// Coarsened primitives

var cOr = lift2(or, abstractValue);
var cAnd = lift2(and, abstractValue);
var cTernary = lift3(ternary, abstractValue);


// Random variables

var erp1 = makeERP([.9, .05, .05], [0, 1, 2]);
var erp2 = makeERP([.05, .05, .9], [0, 1, 2]);
var erp3 = makeERP([.05, .2, .75], [0, 1, 2]);


// Coarsened random variables

var tmp1 = coarsen(erp1, abstractValue);
var abstractERP1 = tmp1[0];
var conditionalERP1 = tmp1[1];

var tmp2 = coarsen(erp2, abstractValue);
var abstractERP2 = tmp2[0];
var conditionalERP2 = tmp2[1];

var tmp3 = coarsen(erp3, abstractValue);
var abstractERP3 = tmp3[0];
var conditionalERP3 = tmp3[1];


// Main program

var ctfProgram = function(){

  var cX = sample(abstractERP1);
  var cY = sample(abstractERP2);
  var cZ = sample(abstractERP3);
  var cOut1 = cOr(cX, cY);
  var cOut2 = cOr(cY, cZ);
  var cScore = cTernary(cAnd(cOut1, cOut2),
                        abstractValue[-1],
                        abstractValue[-2]);
  factor(cScore);

  var x = sample(conditionalERP1(cX));
  var y = sample(conditionalERP2(cY));
  var z = sample(conditionalERP3(cZ));
  var out1 = or(x, y);
  var out2 = or(y, z);
  var score = ternary(and(out1, out2), -1, -2);
  factor(score - cScore);
  return [x, y, z];

}

print(Enumerate(ctfProgram));
</code></pre>
</div>

<p>This distribution is the same as the distribution induced by the concrete program.</p>

<p>Next steps:</p>

<ul>
  <li>Think about what this approach looks like for programs with conditioned random variables</li>
  <li>Use hierarchical coarsening (more than two layers)</li>
  <li>Apply this approach to a image-based model (use downsampled images on coarse layers). Here, we likely won’t be able to construct the maximum entropy distributions explicitly</li>
  <li>Write a program transform that automates the construction of the coarse-to-fine program. What does this look like for recursive programs such as the HMM?</li>
</ul>

<h2 id="dependent-random-variables">Dependent random variables</h2>

<h3 id="direct-dependencies">Direct dependencies</h3>

<p>For direct dependencies, I think I can work out what the distribution for the final dependent random variable must look like (basically, the abstract value constrains the concrete value to a set, and the concrete independent parameter determines the distribution on this set).</p>

<p>Let’s do this first, since we are going to need it for the more complex case of indirect dependencies where deterministic functions can transform parameters before they hit the next random variable.</p>

<p>Here is a simple program with conditioned random variables:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var ternary = function(test, then, other){
  return test ? then : other;
}

var plus = function(x, y){
  return x + y;
}

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}
///

var chooseP = makeERP([.25, .25, .25, .25], [.1, .2, .4, .7])

var program = function(){
  var p0 = sample(chooseP);
  var y = flip(p0);
  var score = ternary(y, -1, -2);
  factor(score);
  return y;
}

print(Enumerate(program))
</code></pre>
</div>

<p>Coarsening for dependent ERPs:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var instantiate = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  var vs = preImage(cV, allVs, abstractValue);
  return vs[randomInteger(vs.length)];
}

var coarsenDependentERP = function(depERP, abstractValue){

  // The params are coarse-grained values. However,
  // we need fine-grained parameter values to construct
  // a real ERP. This can be achieved through sampling or
  // marginalizing. We'll marginalize.
  var getCoarseERP = function(params){
    return Enumerate(
      function(){
        var fineParams = map(
          function(cV){return instantiate(cV, abstractValue);},
		  params);
        return abstractValue[sample(depERP, fineParams)];
      });
  };

  // Now params are fine-grained values, so we can build a
  // concrete independent erp; we just need to restrict the
  // support to values in the support of coarseValue.
  var getFineERP = function(params, coarseValue){
    return Enumerate(
      function(){
        var value = sample(depERP, params);
        factor((abstractValue[value] == coarseValue) ? 0 : -Infinity);
        return value;
      });
  };

  return [getCoarseERP, getFineERP];
}
</code></pre>
</div>

<p>Now let’s try to write the corresponding coarse-to-fine program.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}

var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};

var coarsen = function(erp, abstractValue){

  // Get concrete values and probabilities

  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v));}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue[vp1[0]] == abstractValue[vp2[0]];
    },
    zip(allVs, allPs));

  var groupSymbols = map(
    function(group){
      // group[0][0]: first value in group
      return abstractValue[group[0][0]]},
	groups)

  var groupedVs = map(
    function(group){
      return map(group, first);},
	groups);

  var groupedPs = map(
    function(group){
      return map(group, second);},
	groups);

  // Construct unconditional (abstract) sampler and
  // conditional (concrete) sampler

  var abstractPs = map(sum, groupedPs);
  var abstractSampler = makeERP(abstractPs, groupSymbols);

  var groupERPs = map2(makeERP, groupedPs, groupedVs);
  var getConcreteSampler = function(abstractSymbol){
    var i = indexOf(abstractSymbol, groupSymbols);
    return groupERPs[i];
  }

  return [abstractSampler, getConcreteSampler];

}

var preImage = function(cV, allVs, abstractValue){
  if (allVs.length == 0) {
    return []
  } else {
    var remainder = preImage(cV, allVs.slice(1), abstractValue);
    if (cV == abstractValue[allVs[0]]) {
      return [allVs[0]].concat(remainder);
    } else {
      return remainder;
    }
  }
}

var maxEntERP = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  // get all values that map to cV
  var vs = preImage(cV, allVs, abstractValue);
  // return uniform distribution on these values
  return Enumerate(
    function(){
      return vs[randomInteger(vs.length)];
    });
}


// Coarsening for dependent ERPs

var instantiate = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  var vs = preImage(cV, allVs, abstractValue);
  return vs[randomInteger(vs.length)];
}

var coarsenDependentERP = function(depERP, abstractValue){

  // The params are coarse-grained values. However,
  // we need fine-grained parameter values to construct
  // a real ERP. This can be achieved through sampling or
  // marginalizing. We'll marginalize.
  var getCoarseERP = function(params){
    return Enumerate(
      function(){
        var fineParams = map(
          function(cV){return instantiate(cV, abstractValue);},
		  params);
        return abstractValue[sample(depERP, fineParams)];
      });
  };

  // Now params are fine-grained values, so we can build a
  // concrete independent erp; we just need to restrict the
  // support to values in support of coarseValue.
  var getFineERP = function(params, coarseValue){
    return Enumerate(
      function(){
        var value = sample(depERP, params);
        factor((abstractValue[value] == coarseValue) ? 0 : -Infinity);
        return value;
      });
  };

  return [getCoarseERP, getFineERP];
}


// Do we really not need to marginalize here?

var lift1 = function(f, abstractValue){
  return function(cX){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var x = sample(d1);
    var out = f(x);
    return abstractValue[out];
  }
}

var lift2 = function(f, abstractValue){
  return function(cX, cY){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var out = f(x, y);
    return abstractValue[out];
  }
}

var lift3 = function(f, abstractValue){
  return function(cX, cY, cZ){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var d3 = maxEntERP(cZ, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var z = sample(d3);
    var out = f(x, y, z);
    return abstractValue[out];
  }
}

// Turn special operators into functions

var ternary = function(test, then, other){
  return test ? then : other;
}


///


// Abstraction map

var abstractValue = {
  .1: "a",
  .2: "a",
  .3: "a",
  .4: "a",
  .5: "b",
  .6: "b",
  .7: "b",
  .8: "b",
  true: "c",
  false: "c",
  "-1": -1,
  "-2": -2
}


// Coarsened primitives

var cTernary = lift3(ternary, abstractValue);


// Random variables

var chooseP = makeERP([.25, .25, .25, .25], [.1, .2, .4, .7])
var coin = bernoulliERP;


// Coarsened random variables

var tmp1 = coarsen(chooseP, abstractValue);
var coarseChooseP = tmp1[0];
var fineChooseP = tmp1[1];

var tmp2 = coarsenDependentERP(coin, abstractValue);
var getCoarseCoin = tmp2[0];
var getFineCoin = tmp2[1];


// Main program

var ctfProgram = function(){

  // Coarse program

  var cP0 = sample(coarseChooseP);
  var coarseCoin = getCoarseCoin([cP0]);
  var cY = sample(coarseCoin);
  var cScore = cTernary(cY, abstractValue[-1], abstractValue[-2]);
  factor(cScore);

  // Fine program

  var p0 = sample(fineChooseP(cP0));
  var fineCoin = getFineCoin([p0], cY);
  var y = sample(fineCoin);
  var score = ternary(y, -1, -2);
  factor(score - cScore);
  return y;
}

print(Enumerate(ctfProgram))
</code></pre>
</div>

<p>Next steps:</p>

<ul>
  <li>Prove that this is always correct</li>
  <li>Indirect dependencies (where the erp parameter is transformed by a deterministic function first)</li>
</ul>

<h2 id="dependent-random-variables-revisited">Dependent random variables, revisited</h2>

<p>I believe that the approach described in the previous section doesn’t work in general. However, so far, I don’t know yet why exactly that is. So, let’s proceed as follows:</p>

<ol>
  <li>Create a new fine-grained program</li>
  <li>Apply previous approach, see where it fails</li>
  <li>Apply new factor decomposition approach</li>
  <li>Consider optimizations for factor decomposition approach</li>
</ol>

<h3 id="the-fine-grained-program">The fine-grained program</h3>

<p>I think the previous fine-grained program was too simplistic to thoroughly test coarsening of dependent erps. In particular, on the coarse level, the dependent erp was a delta distribution. Let’s try to write a more complex program, maybe reminiscent of how HMM states are sampled depending on the previous state.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var ternary = function(test, then, other){
  return test ? then : other;
}

var plus = function(x, y){
  return x + y;
}

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}
///


var erp0 = makeERP([.1, .2, .3, .4], ["a", "b", "c", "d"]);

// could replace this with a real dependent erp
var erp1 = function(x){
  var dists = {
    "a" : [.25, .25, .25, .25],
    "b" : [.1, .2, .3, .4],
    "c" : [.2, .2, .3, .3],
    "d" : [.01, .1, .5, .39]
  };
  var vs = ["e", "f", "g", "h"];
  var dist = dists[x];
  var i = discrete(dist);
  return vs[i];
}

var scores = {
  "e" : -1,
  "f" : -1.5,
  "g" : -2,
  "h" : -2.5
}

var getScore = function(x){
  return scores[x];
}

var program = function(){
  var x = sample(erp0);
  var y = erp1(x);
  var score = getScore(y);
  factor(score);
  return y;
}

print(Enumerate(program))

</code></pre>
</div>

<h3 id="coarsening-using-the-previous-approach">Coarsening using the previous approach</h3>

<p>Now let’s coarsen this program using the previous approach. Recall that the previous approach worked as follows:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>var instantiate = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  var vs = preImage(cV, allVs, abstractValue);
  return vs[randomInteger(vs.length)];
}

var coarsenDependentERP = function(depERP, abstractValue){

  // The params are coarse-grained values. However,
  // we need fine-grained parameter values to construct
  // a real ERP. This can be achieved through sampling or
  // marginalizing. We'll marginalize.
  var getCoarseERP = function(params){
    return Enumerate(
      function(){
        var fineParams = map(
          function(cV){return instantiate(cV, abstractValue);},
		  params);
        return abstractValue[sample(depERP, fineParams)];
      });
  };

  // Now params are fine-grained values, so we can build a
  // concrete independent erp; we just need to restrict the
  // support to values in the support of coarseValue.
  var getFineERP = function(params, coarseValue){
    return Enumerate(
      function(){
        var value = sample(depERP, params);
        factor((abstractValue[value] == coarseValue) ? 0 : -Infinity);
        return value;
      });
  };

  return [getCoarseERP, getFineERP];
}
</code></pre>
</div>

<p>In words:</p>

<ol>
  <li>Take the dependent ERP and a value partitioning function</li>
  <li>Compute the coarse erp for an abstract (parameter) value V by:
    <ol>
      <li>sampling uniformly from the possible fine-grained instantiations of V</li>
      <li>sampling from the fine-grained dependent erp using the sampled instantiation</li>
      <li>returning the abstract value corresponding to the sampled instantiation</li>
    </ol>
  </li>
  <li>Compute the fine-grained erp for a concrete (parameter) value v, and coarse return value X by:
    <ol>
      <li>sampling from the fine-grained dependent erp given parameter v</li>
      <li>conditioning on the abstraction of this sampled value being equal to X</li>
    </ol>
  </li>
</ol>

<p>Where is the problem (if any)?</p>

<p>My guess is that the problem comes in when we uniformly sample an instantiation for the abstract value V at the coarse ERP.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>// static
// p(fine1, fine2)
// = p(coarse1)p(fine1|coarse1) p(fine2|fine1) // so far so good
// = p(coarse1)p(fine1|coarse1) p(coarse2|coarse1) p(fine2|coarse2, fine1)
</code></pre>
</div>

<p>In other words, the problem comes in when we sample <code class="highlighter-rouge">coarse2|coarse1</code>. My hunch is that we would need to know which erp <code class="highlighter-rouge">coarse1</code> comes from, so that we can use the “true” instantiation probabilities instead of the uniform instantiation probabilities.</p>

<p>Let’s verify whether this is actually a problem by applying this approach to the model above.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var ternary = function(test, then, other){
  return test ? then : other;
}

var plus = function(x, y){
  return x + y;
}

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}


// Utils

var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};

// Coarsening

var coarsen = function(erp, abstractValue){

  // Get concrete values and probabilities

  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v));}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue[vp1[0]] == abstractValue[vp2[0]];
    },
    zip(allVs, allPs));

  var groupSymbols = map(
    function(group){
      // group[0][0]: first value in group
      return abstractValue[group[0][0]]},
	groups)

  var groupedVs = map(
    function(group){
      return map(group, first);
      },
	groups);

  var groupedPs = map(
    function(group){
      return map(group, second);
      },
	groups);

  // Construct unconditional (abstract) sampler and
  // conditional (concrete) sampler

  var abstractPs = map(sum, groupedPs);
  var abstractSampler = makeERP(abstractPs, groupSymbols);

  var groupERPs = map2(makeERP, groupedPs, groupedVs);
  var getConcreteSampler = function(abstractSymbol){
    var i = indexOf(abstractSymbol, groupSymbols);
    return groupERPs[i];
  }

  return [abstractSampler, getConcreteSampler];

}

var preImage = function(cV, allVs, abstractValue){
  if (allVs.length == 0) {
    return []
  } else {
    var remainder = preImage(cV, allVs.slice(1), abstractValue);
    if (cV == abstractValue[allVs[0]]) {
      return [allVs[0]].concat(remainder);
    } else {
      return remainder;
    }
  }
}

var maxEntERP = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  // get all values that map to cV
  var vs = preImage(cV, allVs, abstractValue);
  // return uniform distribution on these values
  return Enumerate(
    function(){
      return vs[randomInteger(vs.length)];
    });
}


// Coarsening for dependent erps

var instantiate = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  var vs = preImage(cV, allVs, abstractValue);
  console.log(cV);
  return vs[randomInteger(vs.length)];
}

var coarsenDependentERP = function(depERPfunc, abstractValue){

  // The params are coarse-grained values. However,
  // we need fine-grained parameter values to construct
  // a real ERP. This can be achieved through sampling or
  // marginalizing. We'll marginalize.
  var getCoarseERP = function(cV){
    return Enumerate(
      function(){
        var fineParams = instantiate(cV, abstractValue);
        return abstractValue[depERPfunc(fineParams)];
      });
  };

  // Now params are fine-grained values, so we can build a
  // concrete independent erp; we just need to restrict the
  // support to values in the support of coarseValue.
  var getFineERP = function(params, coarseValue){
    return Enumerate(
      function(){
        var value = depERPfunc(params);
        factor((abstractValue[value] == coarseValue) ? 0 : -Infinity);
        return value;
      });
  };

  return [getCoarseERP, getFineERP];
}



// Lifting

var lift1 = function(f, abstractValue){
  return function(cX){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var x = sample(d1);
    var out = f(x);
    return abstractValue[out];
  }
}

var lift2 = function(f, abstractValue){
  return function(cX, cY){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var out = f(x, y);
    return abstractValue[out];
  }
}

var lift3 = function(f, abstractValue){
  return function(cX, cY, cZ){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var d3 = maxEntERP(cZ, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var z = sample(d3);
    var out = f(x, y, z);
    return abstractValue[out];
  }
}


///



// Base-level erps

var erp0 = makeERP([.1, .2, .3, .4], ["a", "b", "c", "d"]);

var erp1 = function(x){
  var dists = {
    "a" : [.25, .25, .25, .25],
    "b" : [.1, .2, .3, .4],
    "c" : [.2, .2, .3, .3],
    "d" : [.01, .1, .5, .39]
  };
  var vs = ["e", "f", "g", "h"];
  var dist = dists[x];
  var i = discrete(dist);
  return vs[i];
}

// Base-level functions

var scores = {
  "e" : -1,
  "f" : -1.5,
  "g" : -2,
  "h" : -2.5
}

var getScore = function(x){
  return scores[x];
}


// Abstraction map

var abstractValue = {
  "a": 1,
  "b": 1,
  "c": 2,
  "d": 2,
  "e": 3,
  "f": 3,
  "g": 4,
  "h": 4,
  "-1": -1,
  "-1.5": -1.5,
  "-2": -2,
  "-2.5": -2.5
}


// Coarse erps

var tmp1 = coarsen(erp0, abstractValue);
var cErp0 = tmp1[0];
var fErp0 = tmp1[1];

var tmp2 = coarsenDependentERP(erp1, abstractValue);
var cErp1 = tmp2[0];
var fErp1 = tmp2[1];

// Lift primitive

var cGetScore = lift1(getScore, abstractValue);


var program = function(){

  var cX = sample(cErp0);
  var cY = sample(cErp1(cX));
  var cScore = cGetScore(cY);
  factor(cScore);

  var x = sample(fErp0(cX));
  var y = sample(fErp1(x, cY));
  var score = getScore(y);
  factor(score - cScore);
  return y;
}

print(Enumerate(program))

</code></pre>
</div>

<p>Yep, the distribution is in fact different from the distribution we would expect.</p>

<h3 id="coarsening-using-factor-decomposition">Coarsening using factor decomposition</h3>

<p>To make the distributions work out, we’ll now apply a different approach:</p>

<ol>
  <li>Rewrite the (fine-grained) program such that all erps are independent, and such that dependencies are only introduced using factors.</li>
  <li>Coarsen the decomposed program using the coarsening for independent erps that we know works.</li>
</ol>

<p>Here is the fine-grained program in factor decomposition form:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var ternary = function(test, then, other){
  return test ? then : other;
}

var plus = function(x, y){
  return x + y;
}

var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}
///


// Random variables

var erp0 = makeERP([.1, .2, .3, .4], ["a", "b", "c", "d"]);
var erp1maxent = makeERP([.25, .25, .25, .25], ["e", "f", "g", "h"]);


// Primitive functions

var getErp1MaxEntScore = function(y){
  return erp1maxent.score([], y);
}

var erp1 = function(x){
  var dists = {
    "a" : [.25, .25, .25, .25],
    "b" : [.1, .2, .3, .4],
    "c" : [.2, .2, .3, .3],
    "d" : [.01, .1, .5, .39]
  };
  var vs = ["e", "f", "g", "h"];
  var dist = dists[x];
  return makeERP(dist, vs);
}

var getErp1Score = function(x, y){
  return erp1(x).score([], y);
}

var getFactorScore = function(y){
  var scores = {
    "e" : -1,
    "f" : -1.5,
    "g" : -2,
    "h" : -2.5
  }
  return scores[y];
}


// Model

var program = function(){
  var x = sample(erp0);
  var y = sample(erp1maxent);
  var score1 = getErp1Score(x, y) - getErp1MaxEntScore(y);
  factor(score1);
  var score2 = getFactorScore(y);
  factor(score2);
  return y;
}

print(Enumerate(program))
</code></pre>
</div>

<p>Note that the distribution is the same as for the original program.</p>

<p>Now that the program only contains independent erps and factors, we can compute the corresponding coarse-to-fine program:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>///fold:
var makeERP = function(ps, vs){
  return Enumerate(function(){return vs[discrete(ps)]});
}

var compose = function(f, g){
  return function(x){
    return f(g(x));
  };
};

var coarsen = function(erp, abstractValue){

  // Get concrete values and probabilities

  var allVs = erp.support([]);
  var allPs = map(function(v){return Math.exp(erp.score([], v));}, allVs);

  // Group distribution based on equivalence classes
  // implied by abstractValue function

  var groups = groupBy(
    function(vp1, vp2){
      return abstractValue[vp1[0]] == abstractValue[vp2[0]];
    },
    zip(allVs, allPs));

  var groupSymbols = map(
    function(group){
      // group[0][0]: first value in group
      return abstractValue[group[0][0]]},
	groups)

  var groupedVs = map(
    function(group){
      return map(group, first);
      },
	groups);

  var groupedPs = map(
    function(group){
      return map(group, second);
      },
	groups);

  // Construct unconditional (abstract) sampler and
  // conditional (concrete) sampler

  var abstractPs = map(sum, groupedPs);
  var abstractSampler = makeERP(abstractPs, groupSymbols);

  var groupERPs = map2(makeERP, groupedPs, groupedVs);
  var getConcreteSampler = function(abstractSymbol){
    var i = indexOf(abstractSymbol, groupSymbols);
    return groupERPs[i];
  }

  return [abstractSampler, getConcreteSampler];

}

var preImage = function(cV, allVs, abstractValue){
  if (allVs.length == 0) {
    return []
  } else {
    var remainder = preImage(cV, allVs.slice(1), abstractValue);
    if (cV == abstractValue[allVs[0]]) {
      return [allVs[0]].concat(remainder);
    } else {
      return remainder;
    }
  }
}

var maxEntERP = function(cV, abstractValue){
  var allVs = Object.keys(abstractValue);
  // get all values that map to cV
  var vs = preImage(cV, allVs, abstractValue);
  // return uniform distribution on these values
  return Enumerate(
    function(){
      return vs[randomInteger(vs.length)];
    });
}

var contains = function(lst, val){
  if (lst.length == 0) {
    return false;
  } else {
    if (lst[0] == val){
      return true;
    } else {
      return contains(lst.slice(1), val)
    }
  }
}

// Do we really not need to marginalize here?

var lift1 = function(f, abstractValue){
  return function(cX){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var x = sample(d1);
    var out = f(x);
    if (contains(Object.keys(abstractValue), out)){
      return abstractValue[out];
    } else {
      return out
    }
  }
}

var lift2 = function(f, abstractValue){
  return function(cX, cY){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var out = f(x, y);
    if (contains(Object.keys(abstractValue), out)){
      return abstractValue[out];
    } else {
      return out
    }
  }
}

var lift3 = function(f, abstractValue){
  return function(cX, cY, cZ){
    var d1 = maxEntERP(cX, abstractValue); // could cache this
    var d2 = maxEntERP(cY, abstractValue); // could cache this
    var d3 = maxEntERP(cZ, abstractValue); // could cache this
    var x = sample(d1);
    var y = sample(d2);
    var z = sample(d3);
    var out = f(x, y, z);
    return abstractValue[out];
  }
}
///


// Abstraction map

var abstractValue = {
  "a": 1,
  "b": 1,
  "c": 2,
  "d": 2,
  "e": 3,
  "f": 3,
  "g": 4,
  "h": 4,
  "-1": -1,
  "-1.5": -1.5,
  "-2": -2,
  "-2.5": -2.5
}


// Random variables

var erp0 = makeERP([.1, .2, .3, .4], ["a", "b", "c", "d"]);
var erp1maxent = makeERP([.25, .25, .25, .25], ["e", "f", "g", "h"]);


// Coarsened random variables

var tmp0 = coarsen(erp0, abstractValue);
var cErp0 = tmp0[0];
var fErp0 = tmp0[1];

var tmp1 = coarsen(erp1maxent, abstractValue);
var cErp1 = tmp1[0];
var fErp1 = tmp1[1];


// Primitive functions

var getErp1MaxEntScore = function(y){
  return erp1maxent.score([], y);
}

var erp1 = function(x){
  var dists = {
    "a" : [.25, .25, .25, .25],
    "b" : [.1, .2, .3, .4],
    "c" : [.2, .2, .3, .3],
    "d" : [.01, .1, .5, .39]
  };
  var vs = ["e", "f", "g", "h"];
  var dist = dists[x];
  return makeERP(dist, vs);
}

var getErp1Score = function(x, y){
  return erp1(x).score([], y);
}

var getFactorScore = function(y){
  var scores = {
    "e" : -1,
    "f" : -1.5,
    "g" : -2,
    "h" : -2.5
  }
  return scores[y];
}


// Coarsened primitives

var cGetErp1MaxEntScore = lift1(getErp1MaxEntScore, abstractValue);
var cGetErp1Score = lift2(getErp1Score, abstractValue);
var cGetFactorScore = lift1(getFactorScore, abstractValue);


// Model

var program = function(){
  var cX = sample(cErp0);
  var cY = sample(cErp1);
  var cScore1 = cGetErp1Score(cX, cY) - cGetErp1MaxEntScore(cY);
  factor(cScore1);
  var cScore2 = cGetFactorScore(cY);
  factor(cScore2);

  var x = sample(fErp0(cX));
  var y = sample(fErp1(cY));
  var score1 = getErp1Score(x, y) - getErp1MaxEntScore(y);
  factor(score1 - cScore1);
  var score2 = getFactorScore(y);
  factor(score2 - cScore2);
  return y;
}

print(Enumerate(program))
</code></pre>
</div>

<p>FIXME: The abstraction for lifting is currently the identity for values that are not in the <code class="highlighter-rouge">abstractValue</code> table; this could easily lead to problems. We might want to consider special-casing scores.</p>

<p>The approach above will also work for indirect dependencies (i.e. dependencies that go through some intermediate function), since such programs can be desugared to independent random variables + factors in the same way.</p>

<p>Next steps:</p>

<ul>
  <li>Consider optimizing the resulting program using <code class="highlighter-rouge">sampleWithFactor</code></li>
  <li>Think about whether clustering values (independent of distribution) will be useful in practice</li>
</ul>



    </div><!-- /.container -->

  </body>
</html>
